{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Event</th>\n",
       "      <th>Result</th>\n",
       "      <th>WhiteElo</th>\n",
       "      <th>BlackElo</th>\n",
       "      <th>AN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Classical</td>\n",
       "      <td>1-0</td>\n",
       "      <td>1901</td>\n",
       "      <td>1896</td>\n",
       "      <td>1. d4 d5 2. c4 c6 3. e3 a6 4. Nf3 e5 5. cxd5 e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Blitz</td>\n",
       "      <td>0-1</td>\n",
       "      <td>1641</td>\n",
       "      <td>1627</td>\n",
       "      <td>1. e4 e5 2. b3 Nf6 3. Bb2 Nc6 4. Nf3 d6 5. d3 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Blitz tournament</td>\n",
       "      <td>1-0</td>\n",
       "      <td>1647</td>\n",
       "      <td>1688</td>\n",
       "      <td>1. e4 d5 2. exd5 Qxd5 3. Nf3 Bg4 4. Be2 Nf6 5....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Correspondence</td>\n",
       "      <td>1-0</td>\n",
       "      <td>1706</td>\n",
       "      <td>1317</td>\n",
       "      <td>1. e3 Nf6 2. Bc4 d6 3. e4 e6 4. Nf3 Nxe4 5. Nd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Blitz tournament</td>\n",
       "      <td>0-1</td>\n",
       "      <td>1945</td>\n",
       "      <td>1900</td>\n",
       "      <td>1. e4 c5 2. Nf3 d6 3. d4 cxd4 4. Nxd4 Nf6 5. N...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Event Result  WhiteElo  BlackElo  \\\n",
       "0          Classical     1-0      1901      1896   \n",
       "1              Blitz     0-1      1641      1627   \n",
       "2   Blitz tournament     1-0      1647      1688   \n",
       "3     Correspondence     1-0      1706      1317   \n",
       "4   Blitz tournament     0-1      1945      1900   \n",
       "\n",
       "                                                  AN  \n",
       "0  1. d4 d5 2. c4 c6 3. e3 a6 4. Nf3 e5 5. cxd5 e...  \n",
       "1  1. e4 e5 2. b3 Nf6 3. Bb2 Nc6 4. Nf3 d6 5. d3 ...  \n",
       "2  1. e4 d5 2. exd5 Qxd5 3. Nf3 Bg4 4. Be2 Nf6 5....  \n",
       "3  1. e3 Nf6 2. Bc4 d6 3. e4 e6 4. Nf3 Nxe4 5. Nd...  \n",
       "4  1. e4 c5 2. Nf3 d6 3. d4 cxd4 4. Nxd4 Nf6 5. N...  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Load data from CSV file\n",
    "file_path = '/Users/chetan/Downloads/chess_games.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Select only the required columns\n",
    "cleaned_df = df[['Event', 'Result', 'WhiteElo', 'BlackElo', 'AN']]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9g/dbdmmkg566z9ggvvd04r5nfm0000gn/T/ipykernel_3598/882683756.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  cleaned_df['Event'] = cleaned_df['Event'].str.strip()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Event</th>\n",
       "      <th>Result</th>\n",
       "      <th>WhiteElo</th>\n",
       "      <th>BlackElo</th>\n",
       "      <th>AN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Classical</td>\n",
       "      <td>1-0</td>\n",
       "      <td>1901</td>\n",
       "      <td>1896</td>\n",
       "      <td>1. d4 d5 2. c4 c6 3. e3 a6 4. Nf3 e5 5. cxd5 e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>Classical</td>\n",
       "      <td>0-1</td>\n",
       "      <td>1457</td>\n",
       "      <td>1869</td>\n",
       "      <td>1. d4 e6 2. c4 f5 3. Nf3 Be7 4. Nc3 Nf6 5. Bg5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>Classical</td>\n",
       "      <td>1-0</td>\n",
       "      <td>1903</td>\n",
       "      <td>1951</td>\n",
       "      <td>1. e4 e5 2. d4 exd4 3. Qxd4 Nc6 4. Qe3 Nf6 5. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>Classical</td>\n",
       "      <td>0-1</td>\n",
       "      <td>1808</td>\n",
       "      <td>2105</td>\n",
       "      <td>1. e4 e5 2. Nf3 Nc6 3. h3 Nf6 4. d3 d5 5. exd5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>Classical</td>\n",
       "      <td>1-0</td>\n",
       "      <td>2090</td>\n",
       "      <td>2032</td>\n",
       "      <td>1. e4 c5 2. Nf3 Nc6 3. c3 e6 4. d4 cxd4 5. cxd...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Event Result  WhiteElo  BlackElo  \\\n",
       "0    Classical    1-0      1901      1896   \n",
       "90   Classical    0-1      1457      1869   \n",
       "116  Classical    1-0      1903      1951   \n",
       "132  Classical    0-1      1808      2105   \n",
       "141  Classical    1-0      2090      2032   \n",
       "\n",
       "                                                    AN  \n",
       "0    1. d4 d5 2. c4 c6 3. e3 a6 4. Nf3 e5 5. cxd5 e...  \n",
       "90   1. d4 e6 2. c4 f5 3. Nf3 Be7 4. Nc3 Nf6 5. Bg5...  \n",
       "116  1. e4 e5 2. d4 exd4 3. Qxd4 Nc6 4. Qe3 Nf6 5. ...  \n",
       "132  1. e4 e5 2. Nf3 Nc6 3. h3 Nf6 4. d3 d5 5. exd5...  \n",
       "141  1. e4 c5 2. Nf3 Nc6 3. c3 e6 4. d4 cxd4 5. cxd...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clean up the 'Event' column\n",
    "cleaned_df['Event'] = cleaned_df['Event'].str.strip()\n",
    "\n",
    "# Filter the DataFrame again\n",
    "new_df = cleaned_df[(cleaned_df['Event'] == 'Classical') & ((cleaned_df['WhiteElo'] > 1800) | (cleaned_df['BlackElo'] > 1800))]\n",
    "\n",
    "# Display the filtered data\n",
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\" ''' import pandas as pd\n",
    "\n",
    "# Load data from CSV file\n",
    "file_path = '/Users/chetan/Downloads/chess_games.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Select only the required columns\n",
    "cleaned_df = df[['Event', 'Result', 'WhiteElo', 'BlackElo', 'AN']]\n",
    "\n",
    "# Clean up the 'Event' column using .loc\n",
    "cleaned_df.loc[:, 'Event'] = cleaned_df['Event'].str.strip()\n",
    "\n",
    "# Filter the DataFrame\n",
    "new_df = cleaned_df[(cleaned_df['Event'] == 'Classical') & ((cleaned_df['WhiteElo'] > 1800) | (cleaned_df['BlackElo'] > 1800))]\n",
    "\n",
    "# Display the filtered data\n",
    "new_df.head() \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Result</th>\n",
       "      <th>AN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1-0</td>\n",
       "      <td>1. d4 d5 2. c4 c6 3. e3 a6 4. Nf3 e5 5. cxd5 e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0-1</td>\n",
       "      <td>1. e4 e5 2. b3 Nf6 3. Bb2 Nc6 4. Nf3 d6 5. d3 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1-0</td>\n",
       "      <td>1. e4 d5 2. exd5 Qxd5 3. Nf3 Bg4 4. Be2 Nf6 5....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1-0</td>\n",
       "      <td>1. e3 Nf6 2. Bc4 d6 3. e4 e6 4. Nf3 Nxe4 5. Nd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0-1</td>\n",
       "      <td>1. e4 c5 2. Nf3 d6 3. d4 cxd4 4. Nxd4 Nf6 5. N...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Result                                                 AN\n",
       "0    1-0  1. d4 d5 2. c4 c6 3. e3 a6 4. Nf3 e5 5. cxd5 e...\n",
       "1    0-1  1. e4 e5 2. b3 Nf6 3. Bb2 Nc6 4. Nf3 d6 5. d3 ...\n",
       "2    1-0  1. e4 d5 2. exd5 Qxd5 3. Nf3 Bg4 4. Be2 Nf6 5....\n",
       "3    1-0  1. e3 Nf6 2. Bc4 d6 3. e4 e6 4. Nf3 Nxe4 5. Nd...\n",
       "4    0-1  1. e4 c5 2. Nf3 d6 3. d4 cxd4 4. Nxd4 Nf6 5. N..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df = cleaned_df[['Result', 'AN']]\n",
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Obtaining dependency information for torch from https://files.pythonhosted.org/packages/d0/db/5d9cbfbc7968d79c5c09a0bc0bc3735da079f2fd07cc10498a62b320a480/torch-2.5.1-cp311-none-macosx_11_0_arm64.whl.metadata\n",
      "  Using cached torch-2.5.1-cp311-none-macosx_11_0_arm64.whl.metadata (28 kB)\n",
      "Requirement already satisfied: filelock in /Users/chetan/anaconda3/lib/python3.11/site-packages (from torch) (3.9.0)\n",
      "Collecting typing-extensions>=4.8.0 (from torch)\n",
      "  Obtaining dependency information for typing-extensions>=4.8.0 from https://files.pythonhosted.org/packages/26/9f/ad63fc0248c5379346306f8668cda6e2e2e9c95e01216d2b8ffd9ff037d0/typing_extensions-4.12.2-py3-none-any.whl.metadata\n",
      "  Using cached typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: networkx in /Users/chetan/anaconda3/lib/python3.11/site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in /Users/chetan/anaconda3/lib/python3.11/site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /Users/chetan/anaconda3/lib/python3.11/site-packages (from torch) (2023.4.0)\n",
      "Collecting sympy==1.13.1 (from torch)\n",
      "  Obtaining dependency information for sympy==1.13.1 from https://files.pythonhosted.org/packages/b2/fe/81695a1aa331a842b582453b605175f419fe8540355886031328089d840a/sympy-1.13.1-py3-none-any.whl.metadata\n",
      "  Using cached sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/chetan/anaconda3/lib/python3.11/site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/chetan/anaconda3/lib/python3.11/site-packages (from jinja2->torch) (2.1.1)\n",
      "Using cached torch-2.5.1-cp311-none-macosx_11_0_arm64.whl (63.9 MB)\n",
      "Using cached sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
      "Using cached typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
      "Installing collected packages: typing-extensions, sympy, torch\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.7.1\n",
      "    Uninstalling typing_extensions-4.7.1:\n",
      "      Successfully uninstalled typing_extensions-4.7.1\n",
      "  Attempting uninstall: sympy\n",
      "    Found existing installation: sympy 1.11.1\n",
      "    Uninstalling sympy-1.11.1:\n",
      "      Successfully uninstalled sympy-1.11.1\n",
      "Successfully installed sympy-1.13.1 torch-2.5.1 typing-extensions-4.12.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chetan/anaconda3/lib/python3.11/site-packages/transformers/utils/generic.py:260: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. d4 d5 2. c4 c6 3. e3 a6 4. Nf3 e5 5. cxd5 e4 6. Ne5 cxd5 7. Qa4+ Bd7 8. Nxd7 Nxd7 9. Nc3 Nf6 10. Qb3 Be7 11. Nxd5 Qa5+ 12. Nc3 O-O 13. Be2 b5 14. O-O Rad8 15. Bd2 Qc7 16. Rac1 Qd6 17. Qc2 Qe6 18. Nb1 Bd6 19. a3 Nb6 20. Qc6 Nfd5 21. Ba5 Rc8 22. Qb7 Qh6 23. h3 Nc4 24. Bxc4 bxc4 25. Qxd5 Rfd8 26. Qxe4 Rd7 27. Bc3 Re7 28. Qf3 Re6 29. Nd2 Rf6 30. Qg4 Re8 31. Ne4 Rg6 32. Qd7 Rf8 33. Nxd6 Rxd6 34. Qc7 Rg6 35. Qh2 Re8 36. d5 f6 37. d6 Rd8 38. Rfd1 1-0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chetan/anaconda3/lib/python3.11/site-packages/transformers/generation/utils.py:1262: UserWarning: Input length of input_ids is 279, but `max_length` is set to 50. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "import torch\n",
    "\n",
    "# Load pre-trained model and tokenizer\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
    "\n",
    "# Function to predict the next move\n",
    "def predict_next_move(input_text, max_length=50):\n",
    "    # Encode the input text\n",
    "    input_ids = tokenizer.encode(input_text, return_tensors='pt')\n",
    "    \n",
    "    # Generate the next move\n",
    "    with torch.no_grad():\n",
    "        output = model.generate(input_ids, max_length=max_length, num_return_sequences=1, pad_token_id=tokenizer.eos_token_id)\n",
    "    \n",
    "    # Decode the output\n",
    "    predicted_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "    return predicted_text\n",
    "\n",
    "# Example usage\n",
    "input_text = final_df.iloc[0]['AN']  # Taking the first row's AN column as input\n",
    "predicted_move = predict_next_move(input_text)\n",
    "print(predicted_move)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the data\n",
    "def preprocess_data(df):\n",
    "    sequences = []\n",
    "    for index, row in df.iterrows():\n",
    "        moves = row['AN'].split()\n",
    "        for i in range(1, len(moves)):\n",
    "            sequences.append((moves[:i], moves[i]))\n",
    "    return sequences\n",
    "\n",
    "sequences = preprocess_data(final_df)\n",
    "\n",
    "# Create a custom dataset\n",
    "class ChessDataset(Dataset):\n",
    "    def __init__(self, sequences):\n",
    "        self.sequences = sequences\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sequences)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        input_seq, target = self.sequences[idx]\n",
    "        return torch.tensor(input_seq), torch.tensor(target)\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "train_sequences, val_sequences = train_test_split(sequences, test_size=0.2, random_state=42)\n",
    "train_dataset = ChessDataset(train_sequences)\n",
    "val_dataset = ChessDataset(val_sequences)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Define the transformer model\n",
    "class TransformerModel(nn.Module):\n",
    "    def __init__(self, vocab_size, d_model, nhead, num_encoder_layers, num_decoder_layers, dim_feedforward, dropout=0.1):\n",
    "        super(TransformerModel, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, d_model)\n",
    "        self.transformer = nn.Transformer(d_model, nhead, num_encoder_layers, num_decoder_layers, dim_feedforward, dropout)\n",
    "        self.fc = nn.Linear(d_model, vocab_size)\n",
    "\n",
    "    def forward(self, src, tgt):\n",
    "        src = self.embedding(src)\n",
    "        tgt = self.embedding(tgt)\n",
    "        output = self.transformer(src, tgt)\n",
    "        output = self.fc(output)\n",
    "        return output\n",
    "\n",
    "# Hyperparameters\n",
    "vocab_size = 1000  # Adjust based on your vocabulary size\n",
    "d_model = 512\n",
    "nhead = 8\n",
    "num_encoder_layers = 6\n",
    "num_decoder_layers = 6\n",
    "dim_feedforward = 2048\n",
    "dropout = 0.1\n",
    "\n",
    "# Initialize the model, loss function, and optimizer\n",
    "model = TransformerModel(vocab_size, d_model, nhead, num_encoder_layers, num_decoder_layers, dim_feedforward, dropout)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for src, tgt in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        output = model(src, tgt)\n",
    "        loss = criterion(output.view(-1, vocab_size), tgt.view(-1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for src, tgt in val_loader:\n",
    "            output = model(src, tgt)\n",
    "            loss = criterion(output.view(-1, vocab_size), tgt.view(-1))\n",
    "            val_loss += loss.item()\n",
    "\n",
    "    print(f'Epoch {epoch+1}, Validation Loss: {val_loss/len(val_loader)}')\n",
    "\n",
    "# Save the model\n",
    "torch.save(model.state_dict(), 'transformer_model.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
